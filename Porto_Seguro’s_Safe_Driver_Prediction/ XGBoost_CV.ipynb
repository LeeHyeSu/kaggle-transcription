{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T07:26:27.530124Z",
     "start_time": "2021-06-17T07:26:27.514073Z"
    }
   },
   "source": [
    "**Kernel**\n",
    "- [XGBoost CV (LB .284)](https://www.kaggle.com/aharless/xgboost-cv-lb-284)\n",
    "\n",
    "**Dataset**\n",
    "- [Porto Seguro’s Safe Driver Prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:20.422317Z",
     "start_time": "2021-06-17T09:13:20.412312Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 400\n",
    "OPTIMIZE_ROUNDS = False\n",
    "LEARNING_RATE = 0.07\n",
    "EARLY_STOPPING_ROUNDS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:20.437718Z",
     "start_time": "2021-06-17T09:13:20.424245Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numba import jit\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numba는 NumPy 배열/함수 및 루프를 사용하는 파이썬 코드에 가장 잘 작동하는 즉석 컴파일러이다. 함수에 일련의 데코레이터를 적용함으로써 Numba는 코드를 컴파일 할 수 있다. Numba로 데코레이트된 함수를 호출하면 해당 함수는 \"즉석\"에서 바로 기계어 코드로 컴파일되고 원래의 기계어 코드 속도로 실행된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:20.453943Z",
     "start_time": "2021-06-17T09:13:20.439785Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute gini\n",
    "# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "\n",
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:35:30.883411Z",
     "start_time": "2021-06-17T09:35:30.874630Z"
    }
   },
   "outputs": [],
   "source": [
    "# Funcitons from olivier's kernel\n",
    "# https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = -eval_gini(labels, preds)\n",
    "    return [('gini', gini_score)]\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "def target_encode(trn_series=None,\n",
    "                  val_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    '''\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior\n",
    "    '''\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    \n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg(['mean', 'count'])\n",
    "    \n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages['count'] - min_samples_leaf) / smoothing))\n",
    "    \n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    \n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages['mean'] * smoothing\n",
    "    averages.drop(['mean', 'count'], axis=1, inplace=True)\n",
    "    \n",
    "    # Apply averages to trn series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on = trn_series.name,\n",
    "        how = 'left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    \n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    \n",
    "    # Apply averages to val series\n",
    "    ft_val_series = pd.merge(\n",
    "        val_series.to_frame(val_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on = val_series.name,\n",
    "        how = 'left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    \n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_val_series.index = val_series.index\n",
    "    \n",
    "    # Apply averages to tst series\n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on = tst_series.name,\n",
    "        how = 'left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    \n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    \n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:25.051106Z",
     "start_time": "2021-06-17T09:13:20.470874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "train_df = pd.read_csv('data/train.csv', na_values=\"-1\")\n",
    "test_df = pd.read_csv('data/test.csv', na_values=\"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:25.066196Z",
     "start_time": "2021-06-17T09:13:25.052250Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features = [\n",
    "    \"ps_car_13\",\n",
    "    \"ps_reg_03\",\n",
    "    \"ps_ind_05_cat\",\n",
    "    \"ps_ind_03\",\n",
    "    \"ps_ind_15\",\n",
    "    \"ps_reg_02\",\n",
    "    \"ps_car_14\",\n",
    "    \"ps_car_12\",\n",
    "    \"ps_car_01_cat\",\n",
    "    \"ps_car_07_cat\",\n",
    "    \"ps_ind_17_bin\",\n",
    "    \"ps_car_03_cat\",\n",
    "    \"ps_reg_01\",\n",
    "    \"ps_car_15\",\n",
    "    \"ps_ind_01\",\n",
    "    \"ps_ind_16_bin\",\n",
    "    \"ps_ind_07_bin\",\n",
    "    \"ps_car_06_cat\",\n",
    "    \"ps_car_04_cat\",\n",
    "    \"ps_ind_06_bin\",\n",
    "    \"ps_car_09_cat\",\n",
    "    \"ps_car_02_cat\",\n",
    "    \"ps_ind_02_cat\",\n",
    "    \"ps_car_11\",\n",
    "    \"ps_car_05_cat\",\n",
    "    \"ps_calc_09\",\n",
    "    \"ps_calc_05\",\n",
    "    \"ps_ind_08_bin\",\n",
    "    \"ps_car_08_cat\",\n",
    "    \"ps_ind_09_bin\",\n",
    "    \"ps_ind_04_cat\",\n",
    "    \"ps_ind_18_bin\",\n",
    "    \"ps_ind_12_bin\",\n",
    "    \"ps_ind_14\"\n",
    "]\n",
    "\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),\n",
    "    ('ps_reg_01', 'ps_car_04_cat')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:29.392321Z",
     "start_time": "2021-06-17T09:13:25.067951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.0"
     ]
    }
   ],
   "source": [
    "# Process data\n",
    "\n",
    "id_test = test_df['id'].values\n",
    "id_train = train_df['id'].values\n",
    "y = train_df['target']\n",
    "\n",
    "start = time.time()\n",
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    name1 = f1 + \"_plus_\" + f2\n",
    "    print('current feature %60s %4d in %5.1f' % (name1, n_c + 1, (time.time() - start) / 60), end='')\n",
    "    print('\\r' * 75, end='')\n",
    "    \n",
    "    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + \"_\" + train_df[f2].apply(lambda x: str(x))\n",
    "    test_df[name1] = test_df[f1].apply(lambda x: str(2)) + \"_\" + test_df[f2].apply(lambda x: str(x))\n",
    "    \n",
    "    # Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n",
    "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
    "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
    "    \n",
    "    train_features.append(name1)\n",
    "    \n",
    "X = train_df[train_features]\n",
    "test_df = test_df[train_features]\n",
    "\n",
    "f_cats = [f for f in X.columns if \"_cat\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:14:06.921094Z",
     "start_time": "2021-06-17T09:14:06.902960Z"
    }
   },
   "outputs": [],
   "source": [
    "y_valid_pred = 0*y\n",
    "y_test_pred = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:14:41.694312Z",
     "start_time": "2021-06-17T09:14:41.681026Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up folds\n",
    "\n",
    "K = 5\n",
    "kf = KFold(n_splits = K, random_state = 1, shuffle = True)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:48:15.710072Z",
     "start_time": "2021-06-17T09:48:15.694004Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up classifier\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators = MAX_ROUNDS,\n",
    "    max_depth = 4,\n",
    "    eval_metric='mlogloss', # objective = \"binary:logistic\",\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    subsample = .8,\n",
    "    min_child_weight = 6,\n",
    "    colsample_bytree = .8,\n",
    "    scale_pos_weight = 1.6,\n",
    "    gamma = 10,\n",
    "    reg_alpha = 8,\n",
    "    reg_lambda = 1.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T10:02:36.305996Z",
     "start_time": "2021-06-17T09:48:15.713014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gini =  0.2851059728784705\n",
      "\n",
      "Fold 1\n",
      "   Gini =  0.28185495483845957\n",
      "\n",
      "Fold 2\n",
      "   Gini =  0.27429910138514\n",
      "\n",
      "Fold 3\n",
      "   Gini =  0.2991202920581566\n",
      "\n",
      "Fold 4\n",
      "   Gini =  0.2857903122299573\n",
      "\n",
      "Gini for full training set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28501477642381845"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run CV\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    # Create data for this fold\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "    X_train, X_valid = X.iloc[train_index, :].copy(), X.iloc[test_index, :].copy()\n",
    "    X_test = test_df.copy()\n",
    "    print(\"\\nFold\", i)\n",
    "    \n",
    "    # Enocode data\n",
    "    for f in f_cats:\n",
    "        X_train[f + \"_avg\"], X_valid[f + \"_avg\"], X_test[f + \"_avg\"] = target_encode(\n",
    "            trn_series = X_train[f],\n",
    "            val_series = X_valid[f],\n",
    "            tst_series = X_test[f],\n",
    "            target = y_train,\n",
    "            min_samples_leaf = 200,\n",
    "            smoothing = 10,\n",
    "            noise_level = 0\n",
    "        )\n",
    "        \n",
    "    # Run model for this fold\n",
    "    if OPTIMIZE_ROUNDS:\n",
    "        eval_set = [(X_valid, y_valid)]\n",
    "        fit_model = model.fit(X_train, y_train,\n",
    "                              eval_set = eval_set,\n",
    "                              eval_metric = gini_xgb,\n",
    "                              early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "                             verbose = False)\n",
    "        print('Best N trees = ', model.best_ntree_limit)\n",
    "        print('Best gini = ', model.best_score)\n",
    "    else:\n",
    "        fit_model = model.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate validation predictions for this fold\n",
    "    pred = fit_model.predict_proba(X_valid)[:, 1]\n",
    "    print(\"   Gini = \", eval_gini(y_valid, pred))\n",
    "    y_valid_pred.iloc[test_index] = pred\n",
    "    \n",
    "    # Accumulate test set predictions\n",
    "    y_test_pred += fit_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    del X_test, X_train, X_valid, y_train\n",
    "    \n",
    "y_test_pred /= K    # Average test set predictions\n",
    "\n",
    "print(\"\\nGini for full training set:\")\n",
    "eval_gini(y, y_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T10:02:45.360560Z",
     "start_time": "2021-06-17T10:02:44.328995Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save validation predictions for stacking/ensembling\n",
    "\n",
    "val = pd.DataFrame()\n",
    "val['id'] = id_train\n",
    "val['target'] = y_valid_pred.values\n",
    "val.to_csv('data/xgb_valid.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T10:02:46.926583Z",
     "start_time": "2021-06-17T10:02:45.360560Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = y_test_pred\n",
    "sub.to_csv('data/xgb_submit.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
